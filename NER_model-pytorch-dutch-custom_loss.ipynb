{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4975e59e-2fc5-4452-8dd9-00c729c0b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import spacy\n",
    "from spacy.training import Example\n",
    "import random\n",
    "\n",
    "from datasets import Dataset\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "# Ensure you have the necessary NLTK tokenizer models downloaded\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58cbc494-eedd-4d55-84a8-4bebe30c2932",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFAutoModelForTokenClassification\n",
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from transformers.keras_callbacks import KerasMetricCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ee86521-2c23-4f75-827c-05928b31bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# folder_path = '/content/drive/MyDrive/UU/Thesis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dea05ca1-440d-4517-aca1-1e6c49660574",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ef3cfbf-f761-48a8-81db-dbdd2688701d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an Excel file into a DataFrame\n",
    "df = pd.read_excel('LCReviewsIntegrated_1962-1994.xlsx', engine='openpyxl')\n",
    "# df = pd.read_excel(folder_path + '/LCReviewsIntegrated_1962-1994.xlsx', engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb5aa31c-73ca-4e26-aab5-a3b7e144714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_spaces(text):\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = re.sub(r'\\s+', ' ', text)\n",
    "    return cleaned_text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6109b689-85d5-40d1-8ddd-2fb0c0311750",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].apply(remove_extra_spaces)\n",
    "df['title1'] = df['title1'].apply(remove_extra_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4157b17-9ea9-47f7-a996-4b3574a5966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(input_string):\n",
    "    # Create a translation table that maps each punctuation character to None\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    # Translate the input string using the translation table\n",
    "    return input_string.translate(translator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7cb13c9-f6ec-4e44-8711-5799d5fe5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_title(x):\n",
    "    if not (type(x.title1) == str):\n",
    "        return np.nan\n",
    "    if not (type(x.content) == str):\n",
    "        return np.nan\n",
    "    if x.title1.lower() in x.content.lower():\n",
    "        return x.title1\n",
    "    \n",
    "    sentence_parts = re.split(r' / | : ', x.title1.lower())\n",
    "    sentence_parts = sorted(sentence_parts, key=len, reverse=True)\n",
    "    for part in sentence_parts:\n",
    "        if part in x.content.lower():\n",
    "            return part\n",
    "        elif remove_punctuation(part) in x.content.lower():\n",
    "            return remove_punctuation(part)\n",
    "\n",
    "    if remove_punctuation(x.title1).lower() in x.content.lower():\n",
    "        return remove_punctuation(x.title1)\n",
    "        \n",
    "    return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecc828c7-ca29-4c6c-9b9e-393b6ad465dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sentence_in_text(full_text, sentence):\n",
    "    start_index = full_text.find(sentence)\n",
    "    if start_index == -1:\n",
    "        print(\"EROR!!!\")\n",
    "        return False\n",
    "    end_index = start_index + len(sentence)\n",
    "    return start_index, end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "140311f3-6370-452b-a74c-37959ac1f14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for index, row in df.iterrows():\n",
    "    result.append(extract_title(row))\n",
    "\n",
    "df['title3'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9fb92165-3353-440b-8918-2bebd9dff278",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df[df['title3'] != 'error']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35afb79-0f32-42ba-933a-ed3cfb872484",
   "metadata": {},
   "source": [
    "## Check what tokens are present before the title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "32a36f9d-32c0-4082-b469-343b589e2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_for_sentence(full_text, sentence):\n",
    "    # Tokenize the full text\n",
    "    tokens = word_tokenize(full_text)\n",
    "    # Find the start and end indices of the sentence in the full text\n",
    "    start_index = full_text.find(sentence)\n",
    "    if start_index == -1:\n",
    "        return None, None\n",
    "    end_index = start_index + len(sentence)\n",
    "    # Tokenize the sentence separately to match tokens exactly\n",
    "    sentence_tokens = word_tokenize(sentence)\n",
    "    # Initialize mask with zeros\n",
    "    mask = [0] * len(tokens)\n",
    "    # Loop through the full text tokens to set the mask\n",
    "    sentence_pos = 0\n",
    "    for i, token in enumerate(tokens):\n",
    "        if sentence_pos < len(sentence_tokens) and token == sentence_tokens[sentence_pos]:\n",
    "            # Check if the full sequence matches and ensure it doesn't go out of bounds\n",
    "            if i + len(sentence_tokens) - sentence_pos <= len(tokens) and \\\n",
    "                all(tokens[i + j] == sentence_tokens[sentence_pos + j] for j in range(len(sentence_tokens) - sentence_pos)):\n",
    "                # Mark the mask for the length of the sentence tokens\n",
    "                mask[i:i + len(sentence_tokens)] = [1] * len(sentence_tokens)\n",
    "                break\n",
    "            else:\n",
    "                # Increment if it's not a full sequence match\n",
    "                sentence_pos += 1\n",
    "        elif token == sentence_tokens[0]:  # Reset if it's the beginning of sentence tokens\n",
    "            sentence_pos = 0\n",
    "    return tokens, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fec478bd-e1c4-45cb-afdb-2af96f4f3afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"ner\"  # Should be one of \"ner\", \"pos\" or \"chunk\"\n",
    "# model_checkpoint = \"distilbert-base-uncased\"\n",
    "model_checkpoint = \"Babelscape/wikineural-multilingual-ner\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3e2a3b9-ce8f-4faf-9baa-24c067f38adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['O', 'I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f53e4847-c14e-43ac-ae7d-d1d6352b64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_set(samples):\n",
    "    data = []\n",
    "\n",
    "    for sample in samples:\n",
    "        unique_content_df = df_clean[df_clean['content'] == sample]\n",
    "        masks = []\n",
    "    \n",
    "        review = remove_punctuation(sample.lower())\n",
    "    \n",
    "        for index, row in unique_content_df.iterrows():\n",
    "            book = remove_punctuation(row['title3'].lower())\n",
    "            \n",
    "            tokens, mask = create_mask_for_sentence(review, book)  # Assuming this returns a mask of the same length as tokens\n",
    "            masks.append(mask)\n",
    "        masks = np.bitwise_or.reduce(np.array(masks), axis=0)\n",
    "        mask[mask == 0] = \"O\"\n",
    "        mask[mask == 1] = \"I\"\n",
    "        \n",
    "        data.append({\n",
    "            \"tokens\": tokens,\n",
    "            \"ner_tags\": masks\n",
    "        })\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52c87fb3-4156-4edf-b034-3aaa9f51b93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.random.choice(df_clean['content'].unique(), size=50, replace=False)\n",
    "# samples = df_clean['content'].unique()[:10000]\n",
    "\n",
    "train_dataset = Dataset.from_list(create_data_set(samples[:int(len(samples) * 0.8)]))\n",
    "val_dataset = Dataset.from_list(create_data_set(samples[int(len(samples) * 0.8):]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93c61150-d612-4060-875f-d2466de108cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f9ebcb9a-38ce-406a-ab9d-1205fec0979f",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"tokens\"], truncation=True, is_split_into_words=True\n",
    "    )\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{task}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "482ebb52-8591-44c1-ade3-7d7cde9b57e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 298.78 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 129.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 40\n",
       "})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset_train = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_dataset_val = val_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "\n",
    "tokenized_dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62b103e7-94c4-4ad2-88c0-e0148dc72be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niels\\miniconda3\\Lib\\site-packages\\datasets\\load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    total_count_O = 0\n",
    "    total_count_I = 0\n",
    "    for pred in true_predictions:\n",
    "        total_count_O = total_count_O + sum(s.count(\"O\") for s in pred)\n",
    "        total_count_I = total_count_I + sum(s.count(\"I\") for s in pred)\n",
    "\n",
    "\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"total_count_O\": total_count_O,\n",
    "        \"total_count_I\": total_count_I,\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4a254f89-f828-488e-8d24-e6d4f15ef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4eca33a-b0f4-451e-8a0e-b4ba61612040",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at Babelscape/wikineural-multilingual-ner and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint, num_labels=2, ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a6d23163-f800-4afd-b9b1-0d358f13bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, smooth=1.):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.smooth = smooth\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        # Flatten predictions and labels\n",
    "        logits = logits.view(-1, 2)  # Assuming 2 classes\n",
    "        targets = targets.view(-1)\n",
    "\n",
    "        # Masking -100 labels\n",
    "        valid_indices = (targets != -100)\n",
    "        logits = logits[valid_indices]\n",
    "        targets = targets[valid_indices]\n",
    "\n",
    "        intersection = torch.sum(logits[:, 1] * targets)\n",
    "        union = torch.sum(logits[:, 1]) + torch.sum(targets)\n",
    "\n",
    "        dice_score = (2. * intersection + self.smooth) / (union + self.smooth)\n",
    "        dice_loss = 1 - dice_score\n",
    "\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1e89c5e-ebaf-47bc-ae82-9a1630efa6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(Trainer):\n",
    "    # def compute_loss(self, model, inputs, return_outputs=False):\n",
    "    # \"\"\" Custom weighted CrossEntropyLoss\"\"\"\n",
    "    #     labels = inputs.pop(\"labels\")\n",
    "    #     outputs = model(**inputs)\n",
    "    #     logits = outputs[0]\n",
    "\n",
    "    #     # Reshape logits to [batch_size * sequence_length, num_classes]\n",
    "    #     logits = logits.view(-1, logits.size(-1))\n",
    "        \n",
    "    #     # Reshape labels to [batch_size * sequence_length]\n",
    "    #     labels = labels.view(-1)\n",
    "        \n",
    "    #     class_weights = torch.tensor([0.5, 28.27], dtype=torch.float32)\n",
    "    #     loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        \n",
    "    #     loss = loss_fn(logits, labels)\n",
    "        \n",
    "    #     return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \"\"\" DICE LOSS \"\"\"\n",
    "        # TODO: IGNORE -100 labels\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits  # Assuming logits are stored in outputs.logits\n",
    "    \n",
    "        # Compute loss using DiceLoss\n",
    "        loss_fn = DiceLoss(smooth=1.2)\n",
    "        loss = loss_fn(logits, labels)\n",
    "    \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "121fa8b9-abaa-4788-b671-9d111c46764a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=12,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='f1',\n",
    "    greater_is_better=True,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f8932fa3-a7c3-4be7-be84-c3ec03f31892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Niels\\miniconda3\\Lib\\site-packages\\accelerate\\accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create a custom Trainer instance\n",
    "trainer = MyTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset_train,\n",
    "    eval_dataset=tokenized_dataset_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "896015c3-31af-4b98-941e-8d827be588cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df\n",
    "# del df_clean\n",
    "# del train_dataset\n",
    "# del val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d5b0ba9d-fc0b-4161-a440-39bf13f7a759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 03:57, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Total Count O</th>\n",
       "      <th>Total Count I</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.868758</td>\n",
       "      <td>0</td>\n",
       "      <td>4947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.979026</td>\n",
       "      <td>0</td>\n",
       "      <td>4947</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=0.9679167866706848, metrics={'train_runtime': 274.2062, 'train_samples_per_second': 0.292, 'train_steps_per_second': 0.029, 'total_flos': 20903740538880.0, 'train_loss': 0.9679167866706848, 'epoch': 2.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65218817-fd42-491d-a88c-a53f75ee450f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec8f4d6-017c-4d73-aebd-0dfaf8123ecc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad66b3a-a7c7-487e-a7df-5f4aabb44ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ab1052-c9ee-41b9-a5c6-5cd58388c77a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42541d7-7a9f-4627-9db7-5035e8493a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c96c7-a1a2-4a69-8f9b-3eeae799fad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c666e29-37cc-4995-82cd-bf3917f611c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28deab19-d28e-4dda-b503-dc3a4a1aee8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f904b1-b79d-4676-903c-c7926f27c1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
